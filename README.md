# ClarityAI
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)

ClarityAI is a Python package designed to empower machine learning practitioners with a range of interpretability methods to enhance the transparency and explainability of their CNN models. Currently, ClarityAI can calculate attention and saliency maps.

## Examples
For a brain tumor MRI scan, the attention maps of different layers of a CNN generated by ClarityAI could look like this:
![Attention Map for MRI Scan](https://github.com/JasmineZhangxyz/clarityai-pypkg/blob/main/examples/attention_map_ex_img.png)

This shows which parts of the image the CNN is focusing on and helps explain the CNN.

Similarly, here is what the saliency map for another MRI scan could look like:
![Saliency Map for MRI Scan](https://github.com/JasmineZhangxyz/clarityai-pypkg/blob/main/examples/saliency_map_ex_img.png)

## Installation + Usage
You can install ClarityAI using pip:
```
pip install ClarityAI==1.0.0
```
For more information, please refer to our [wiki](https://github.com/JasmineZhangxyz/clarityai-pypkg/wiki) for detailed instructions.

## Features
* Documentation for attention map generation can be found [here](https://github.com/JasmineZhangxyz/clarityai-pypkg/wiki/Attention-Maps)
* Documentation for saliency map generation can be found [here](https://github.com/JasmineZhangxyz/clarityai-pypkg/wiki/Saliency-Maps)

## Limitations
ClarityAI is designed to help users quickly integrate interpretability methods into their personal projects. However, ClarityAI is just a tool meant to help users - not replace users' own judgments on interpretability and ethical use cases of their ML models.

Please also note that ClarityAI is a package created for fun/educational purposes! There exist several popular interpretability libraries available in the Python ecosystem, which are much better designed and maintained, such as [SHAP](https://shap.readthedocs.io/en/latest/), [LIME](https://github.com/marcotcr/lime), [Yellowbrick](https://www.scikit-yb.org/en/latest/), and [InterpretML](https://github.com/interpretml/interpret).
